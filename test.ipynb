{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input setup\n",
    "\n",
    "loan_app_name = \"loan_application_form.docx\"\n",
    "cr_name = \"industrial_license.pdf\"\n",
    "il_name = \"industrial_license.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/loan_analysis_app/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from scripts.document_ext import Data_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test-1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert /home/ubuntu/loan_analysis_app/data/loan_application_form.docx -> /home/ubuntu/loan_analysis_app/data/loan_application_form.pdf using filter : writer_pdf_Export\n",
      "Overwriting: /home/ubuntu/loan_analysis_app/data/loan_application_form.pdf\n",
      "D1\n",
      "D2\n",
      "D3\n",
      "D4\n"
     ]
    }
   ],
   "source": [
    "data = Data_extractor().get(loan_app_name, cr_name, il_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": {\n",
      "        \"Paper Cups\": {\n",
      "            \"Year 2024\": 500,\n",
      "            \"Year 2025\": 800,\n",
      "            \"Year 2026\": 800,\n",
      "            \"Year 2027\": 900,\n",
      "            \"Year 2028\": 900\n",
      "        },\n",
      "        \"Paper Bowels\": {\n",
      "            \"Year 2024\": 100,\n",
      "            \"Year 2025\": 200,\n",
      "            \"Year 2026\": 50,\n",
      "            \"Year 2027\": 500,\n",
      "            \"Year 2028\": 600\n",
      "        }\n",
      "    }\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'Paper Cups': {'Year 2024': 500, 'Year 2025': 800, 'Year 2026': 800, 'Year 2027': 900, 'Year 2028': 900}, 'Paper Bowels': {'Year 2024': 100, 'Year 2025': 200, 'Year 2026': 50, 'Year 2027': 500, 'Year 2028': 600}}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# If you're using the Python REPL tool, note it has moved to `langchain_experimental`\n",
    "from langchain_experimental.tools import PythonREPLTool\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Now retrieve the key from the environment\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "# -------------------------------------------------------------------\n",
    "# 1. System instructions (the multi-step prompt).\n",
    "# -------------------------------------------------------------------\n",
    "system_instructions = \"\"\"\\\n",
    "You are a smart business analysis tool provided with 'Tables of loan application' and 'Market Data'.\n",
    "You have access to a math tool for calculations when necessary.\n",
    "\n",
    "Follow these steps:\n",
    "1. identify Table '2.8 Expected sales volume* (for each targeted market) during the first five years of project life' from 'Tables of loan application'.\n",
    "2. Extract the yearly data for all the products contaiing in the table in a well structured JSON format.\n",
    "3. Calcule the sales growth rate for each product(In percentage) for each year and return it as output in json for each product anually.\n",
    "\n",
    "No additional text or formatting is allowed beyond these JSON objects. The data for analysis is given as under;\n",
    "\"\"\"\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 2. Human template\n",
    "# -------------------------------------------------------------------\n",
    "human_template = \"\"\"\\\n",
    "'Tables of loan application':\n",
    "{tables}\n",
    "\"\"\"\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 3. LLM (OpenAI Chat)\n",
    "# -------------------------------------------------------------------\n",
    "llm = ChatOpenAI(\n",
    "    model_name=\"gpt-3.5-turbo\",\n",
    "    temperature=0.0,\n",
    "    openai_api_key=openai_api_key\n",
    ")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 4. Define the Python REPL tool (if needed for calculations).\n",
    "# -------------------------------------------------------------------\n",
    "python_repl_tool = PythonREPLTool()\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 5. Initialize the agent\n",
    "# -------------------------------------------------------------------\n",
    "tools = [python_repl_tool]\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 6. A function to run the agent using a single string input.\n",
    "# -------------------------------------------------------------------\n",
    "def analyze_growth_discrepancies(tables: str, market_data: str) -> str:\n",
    "    \"\"\"\n",
    "    Takes the text for 'Tables of loan application' and 'Market Data',\n",
    "    and returns the JSON objects as a string (with no extra text)\n",
    "    according to the instructions.\n",
    "    \"\"\"\n",
    "    # Combine both system instructions and the user data into one string:\n",
    "    final_prompt = (\n",
    "        f\"{system_instructions}\\n\"\n",
    "        + human_template.format(tables=tables)\n",
    "    )\n",
    "\n",
    "    # Pass the final prompt to the agent via the `run` method\n",
    "    # which expects either a single string or {'input': ...}\n",
    "    response = agent.run({\"input\": final_prompt, \"chat_history\": []})\n",
    "    return response\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 7. Example usage\n",
    "# -------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    example_tables = data['loan_app_tables']\n",
    "    example_market_data = data[\"market_data\"]\n",
    "\n",
    "    final_json_output = analyze_growth_discrepancies(example_tables, example_market_data)\n",
    "    print(final_json_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Paper Cups': {'Year 2024': 500,\n",
       "  'Year 2025': 800,\n",
       "  'Year 2026': 800,\n",
       "  'Year 2027': 900,\n",
       "  'Year 2028': 900},\n",
       " 'Paper Bowels': {'Year 2024': 100,\n",
       "  'Year 2025': 200,\n",
       "  'Year 2026': 50,\n",
       "  'Year 2027': 500,\n",
       "  'Year 2028': 600}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_json_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_experimental.tools import PythonREPLTool\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "\n",
    "class ai_tool:\n",
    "    def __init__(self, model=\"gpt-4o\", temperature=0):\n",
    "        \"\"\"\n",
    "        Initialize the SmartAnalysisAgent with model configuration and validate OpenAI API key.\n",
    "        \"\"\"\n",
    "        self._load_and_validate_api_key()\n",
    "        self.llm = ChatOpenAI(model=model, temperature=temperature)\n",
    "        self.math_agent = initialize_agent(\n",
    "            tools=[PythonREPLTool()],\n",
    "            llm=self.llm,\n",
    "            agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "            # handle_parse_errors=True,\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def _load_and_validate_api_key():\n",
    "        \"\"\"\n",
    "        Load and validate the OpenAI API key from the .env file.\n",
    "        \"\"\"\n",
    "        load_dotenv()\n",
    "        api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "        if not api_key:\n",
    "            raise ValueError(\"OpenAI API key not found. Please set it in your .env file.\")\n",
    "        os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "\n",
    "    def analyse(self, inputs: dict):\n",
    "        \"\"\"\n",
    "        Run an LLM-based analysis on tables provided in markdown format.\n",
    "        \n",
    "        Args:\n",
    "            inputs (dict): A dictionary containing:\n",
    "                - \"tables\": List of tables in markdown format as strings.\n",
    "                - \"analysis_guidelines\": Guidelines for the analysis.\n",
    "                - \"output_guidelines\": Guidelines for the output formatting.\n",
    "\n",
    "        Returns:\n",
    "            str: Analysis result from the LLM.\n",
    "        \"\"\"\n",
    "        # Validate input keys\n",
    "        step_1_keys = {\"tables\", \"prompt\", \"industrial_licence\", \"commercial_registration\", \"market_data\"}\n",
    "        step_2_keys = {\"compile_prompt\", \"input_payload\"}\n",
    "\n",
    "        if step_1_keys.issubset(inputs.keys()):\n",
    "            if inputs[\"prompt\"][\"task_number\"]==\"2\":\n",
    "                # Combine inputs into a structured prompt\n",
    "                prompt_template = \"\"\"\n",
    "                {prompt}\n",
    "\n",
    "                **Tables of loan application**:\n",
    "                {tables}\n",
    "\n",
    "                **Commercial Registration**:\n",
    "                {commercial_registration}\n",
    "\n",
    "                **Industrial License**:\n",
    "                {industrial_licence}\n",
    "                \"\"\"\n",
    "                prompt_input = [\"tables\", \"prompt\", \"industrial_licence\", \"commercial_registration\"]\n",
    "                if isinstance(inputs[\"tables\"], dict):\n",
    "                    tables = json.dumps(inputs[\"tables\"]['1. PROJECT DATA'])\n",
    "                else:\n",
    "                    tables = inputs[\"tables\"]\n",
    "\n",
    "                llm_input = {\n",
    "                \"prompt\": inputs[\"prompt\"][\"prompt\"],\n",
    "                \"tables\": tables,\n",
    "                \"commercial_registration\": \"\\n\\n\"+ inputs[\"commercial_registration\"],\n",
    "                \"industrial_licence\": \"\\n\\n\"+ inputs[\"industrial_licence\"]\n",
    "                }\n",
    "\n",
    "            elif inputs[\"prompt\"][\"task_number\"]==\"4\":\n",
    "                    # Combine inputs into a structured prompt\n",
    "                    prompt_template = \"\"\"\n",
    "                    {prompt}\n",
    "\n",
    "                    **Tables of loan application**:\n",
    "                    {tables}\n",
    "                    \"\"\"\n",
    "                    prompt_input = [\"tables\", \"prompt\"]\n",
    "                    if isinstance(inputs[\"tables\"], dict):\n",
    "                        tables = json.dumps({x:y for x,y in inputs[\"tables\"].items() if x in ['1. PROJECT DATA', '2. MARKETING INFORMATION', \"3. TECHNICAL INFORMATION\"]})\n",
    "                    else:\n",
    "                         tables = inputs[\"tables\"]\n",
    "                    llm_input = {\n",
    "                    \"prompt\": inputs[\"prompt\"][\"prompt\"],\n",
    "                    \"tables\": tables\n",
    "                    }\n",
    "\n",
    "            elif inputs[\"prompt\"][\"task_number\"]==\"5\":\n",
    "                    # Combine inputs into a structured prompt\n",
    "                    prompt_template = \"\"\"\n",
    "                    {prompt}\n",
    "\n",
    "                    **Tables of loan application**:\n",
    "                    {tables}\n",
    "                    \"\"\"\n",
    "                    prompt_input = [\"tables\", \"prompt\"]\n",
    "                    if isinstance(inputs[\"tables\"], dict):\n",
    "                        tables = json.dumps({x:y for x,y in inputs[\"tables\"].items() if x in ['2. MARKETING INFORMATION']})\n",
    "                    else:\n",
    "                         tables = inputs[\"tables\"]\n",
    "                    llm_input = {\n",
    "                    \"prompt\": inputs[\"prompt\"][\"prompt\"],\n",
    "                    \"tables\": tables,\n",
    "                    }\n",
    "\n",
    "            elif inputs[\"prompt\"][\"task_number\"]==\"6\":\n",
    "                # Combine inputs into a structured prompt\n",
    "                prompt_template = \"\"\"\n",
    "                {prompt}\n",
    "\n",
    "                **Tables**:\n",
    "                {tables}\n",
    "\n",
    "                **Market Data**:\n",
    "                {market_data}\n",
    "                \"\"\"\n",
    "                prompt_input = [\"tables\", \"prompt\", \"market_data\"]\n",
    "                if isinstance(inputs[\"tables\"], dict):\n",
    "                    tables = json.dumps({x:y for x,y in inputs[\"tables\"].items() if x in ['1. PROJECT DATA', '2. MARKETING INFORMATION', \"3. TECHNICAL INFORMATION\"]})\n",
    "                else:\n",
    "                     tables = inputs[\"tables\"]\n",
    "                llm_input = {\n",
    "                \"prompt\": inputs[\"prompt\"][\"prompt\"],\n",
    "                \"tables\": tables,\n",
    "                \"market_data\": \"\\n\\n\"+ inputs[\"market_data\"]\n",
    "                }\n",
    "                \n",
    "            else:\n",
    "                # Combine inputs into a structured prompt\n",
    "                prompt_template = \"\"\"\n",
    "                {prompt}\n",
    "\n",
    "                **Tables**:\n",
    "                {tables}\n",
    "                \"\"\"\n",
    "                prompt_input = [\"tables\", \"prompt\"]\n",
    "                if isinstance(inputs[\"tables\"], dict):\n",
    "                     tables = json.dumps(inputs[\"tables\"])\n",
    "                else:\n",
    "                     tables = inputs[\"tables\"]\n",
    "                \n",
    "                llm_input = {\n",
    "                \"prompt\": inputs[\"prompt\"][\"prompt\"],\n",
    "                \"tables\": tables,\n",
    "                }\n",
    "\n",
    "        elif step_2_keys.issubset(inputs.keys()):\n",
    "                # Combine inputs into a structured prompt\n",
    "                prompt_template = \"\"\"\n",
    "                {prompt}\n",
    "\n",
    "                **Input Payload**:\n",
    "                {input_payload}\n",
    "                \"\"\"\n",
    "                prompt_input = [\"input_payload\", \"prompt\"]\n",
    "                llm_input = {\n",
    "                \"prompt\": inputs[\"compile_prompt\"],\n",
    "                \"input_payload\": \"\\n\\n\".join(inputs[\"input_payload\"]),\n",
    "                }\n",
    "\n",
    "        elif not step_1_keys.issubset(inputs.keys()):\n",
    "            raise ValueError(f\"Input dictionary must contain keys: {step_1_keys}\")\n",
    "        else:\n",
    "            raise ValueError(f\"Input dictionary must contain keys: {step_1_keys}\")\n",
    "        \n",
    "        prompt = PromptTemplate(\n",
    "            input_variables=prompt_input,\n",
    "            template=prompt_template.strip()\n",
    "        )\n",
    "        if inputs[\"prompt\"][\"task_number\"]==\"6\":\n",
    "             prompt_formatted = prompt.format(prompt=llm_input[\"prompt\"],\n",
    "                                               tables=llm_input[\"tables\"],\n",
    "                                                 market_data=llm_input[\"market_data\"])\n",
    "             response = self.math_agent.run({\"input\": prompt_formatted, \"chat_history\": []})\n",
    "             return response\n",
    "        else:\n",
    "            chain = prompt | self.llm\n",
    "            result = chain.invoke(input=llm_input)\n",
    "            return result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Extraction Completed!\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": [\n",
      "        {\n",
      "            \"Perspective\": \"Market\",\n",
      "            \"Request\": \"Please provide the basis and reasoning for your projected 0% growth rate for Paper Bowels in 2026 as mentioned in Table 2.8, while the market shows a 4% growth rate.\"\n",
      "        },\n",
      "        {\n",
      "            \"Perspective\": \"Market\",\n",
      "            \"Request\": \"Please revise your sales estimates for Paper Bowels in 2026 to include an appropriate growth percentage in Table 2.8, as the market shows a 4% growth rate.\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ai_agent = ai_tool()\n",
    "l_appt = data[\"loan_app_tables\"]\n",
    "il = data[\"industrial_licence\"]\n",
    "cr = data[\"commercial_registration\"]\n",
    "md = data[\"market_data\"]\n",
    "\n",
    "print(\"Data Extraction Completed!\")\n",
    "\n",
    "input = prompts\n",
    "all_results = []\n",
    "for index, prompt in enumerate([input[5]]):\n",
    "    inputs = {\n",
    "    \"prompt\": prompt,\n",
    "    \"tables\": l_appt,\n",
    "    \"industrial_licence\": il,\n",
    "    \"commercial_registration\": cr,\n",
    "    \"market_data\": json.dumps(md, indent=4)\n",
    "    }\n",
    "\n",
    "    analysis_result = ai_agent.analyse(inputs)\n",
    "    all_results.append(analysis_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Perspective': 'Market',\n",
       "  'Request': 'Please provide the basis and reasoning for your projected 0% growth rate for Paper Bowels in 2026 as mentioned in Table 2.8, while the market shows a 4% growth rate.'},\n",
       " {'Perspective': 'Market',\n",
       "  'Request': 'Please revise your sales estimates for Paper Bowels in 2026 to include an appropriate growth percentage in Table 2.8, as the market shows a 4% growth rate.'}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
